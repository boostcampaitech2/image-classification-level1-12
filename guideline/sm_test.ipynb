{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "6e5262017548a2b455e3c33d8630dbac676c51a278f558e9b73cd2cf5fc8a1af"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MakeLocateDataFrame():\n",
    "    \n",
    "    def __init__(self, type: bool):\n",
    "\n",
    "        self.type = type\n",
    "        self.root = r'/opt/ml/data/'\n",
    "        if self.type:\n",
    "            self.root += 'train'\n",
    "        else:\n",
    "            self.root += 'eval'\n",
    "\n",
    "    def get_csv(self):\n",
    "        datas = None\n",
    "\n",
    "        if self.type:\n",
    "            datas = pd.read_csv(self.root+'/train.csv')\n",
    "            datas = datas.drop(['race','id'],axis=1)\n",
    "\n",
    "        else:\n",
    "            datas = pd.read_csv(self.root+'/info.csv')\n",
    "\n",
    "        return datas\n",
    "\n",
    "    def make_image_locate_frame(self, datas):\n",
    "        \n",
    "        labeled_dict = None\n",
    "        #train = True 인 경우\n",
    "        if self.type:\n",
    "            # 이미지 경로를 담은 리스트 생성\n",
    "            image_locate = [self.root+'/images/'+i for i in datas['path']]\n",
    "            images = []\n",
    "            # 경로 안에 있는 숨김 파일은 제거하고 이미지만 저장\n",
    "            for i in image_locate:\n",
    "                temp = []\n",
    "                for j in os.listdir(i):\n",
    "                    if not j[0] == '.':\n",
    "                        temp.append(i+'/'+j)\n",
    "                images.append(temp)\n",
    "            # 파일 이름으로 클래스를 구분하기 위한 문자\n",
    "            file_name_string = 'min'\n",
    "            #새롭게 반환할 데이터 프레임의 틀\n",
    "            labeled_dict = {\"label\": [],\n",
    "                            \"gender\": [],\n",
    "                            \"age\": [],\n",
    "                            \"locate\": []}\n",
    "\n",
    "            for image in images:\n",
    "                for j in image:\n",
    "                    #/opt/ml/data/train/images/000002_female_Asian_52/normal.jpg 자른 것\n",
    "                    get_locate_file = j.split('/')\n",
    "                    #가장 끝의 파일은 이미지 이름이다.\n",
    "                    label = file_name_string.index(get_locate_file[-1][0])\n",
    "                    start = label * 6\n",
    "                    #000002_female_Asian_52 잘라서 굳이 위에 선언한 데이터 불러오지 않고 수행\n",
    "                    _, sex, _, age = get_locate_file[-2].split('_')\n",
    "                    age = int(age)\n",
    "                    if sex == 'female':\n",
    "                        start +=3\n",
    "                    if age < 30:\n",
    "                        pass\n",
    "                    elif age < 60:\n",
    "                        start +=1\n",
    "                    else:\n",
    "                        start +=2\n",
    "                    labeled_dict['label'].append(start)\n",
    "                    labeled_dict['gender'].append(sex)\n",
    "                    labeled_dict['age'].append(age)\n",
    "                    labeled_dict['locate'].append(j)\n",
    "\n",
    "            labeled_dict = pd.DataFrame(labeled_dict, columns=labeled_dict.keys())\n",
    "\n",
    "        else:\n",
    "            datas['locate'] = [self.root+'/images/'+i for i in datas['ImageID']]\n",
    "            labeled_dict = datas\n",
    "\n",
    "        return labeled_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "30대 이전:\nlabel     8967\ngender    8967\nage       8967\nlocate    8967\ndtype: int64\n60대 이전: \nlabel     8589\ngender    8589\nage       8589\nlocate    8589\ndtype: int64\n60대: \nlabel     1344\ngender    1344\nage       1344\nlocate    1344\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "a = MakeLocateDataFrame(True)\n",
    "\n",
    "data = a.get_csv()\n",
    "# data\n",
    "loc = a.make_image_locate_frame(data)\n",
    "data = a.make_image_locate_frame(data)\n",
    "\n",
    "\n",
    "print(f\"30대 이전:\\n{data.query(f'age < 30').count()}\")\n",
    "print(f\"60대 이전: \\n{data.query(f'(age < 60) & (age >=30)').count()}\")\n",
    "print(f\"60대: \\n{data.query(f'age == 60').count()}\")\n",
    "\n",
    "over_60 = data.query('age==60')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n/opt/ml/data/train/images/001047_male_Asian_60/mask4.jpg\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       label  gender  age                                             locate\n",
       "2912       2    male   60  /opt/ml/data/train/images/001038_male_Asian_60...\n",
       "2913       2    male   60  /opt/ml/data/train/images/001038_male_Asian_60...\n",
       "2914       8    male   60  /opt/ml/data/train/images/001038_male_Asian_60...\n",
       "2915       2    male   60  /opt/ml/data/train/images/001038_male_Asian_60...\n",
       "2916       2    male   60  /opt/ml/data/train/images/001038_male_Asian_60...\n",
       "...      ...     ...  ...                                                ...\n",
       "15521     11  female   60  /opt/ml/data/train/images/005515_female_Asian_...\n",
       "15522      5  female   60  /opt/ml/data/train/images/005515_female_Asian_...\n",
       "15523      5  female   60  /opt/ml/data/train/images/005515_female_Asian_...\n",
       "15524      5  female   60  /opt/ml/data/train/images/005515_female_Asian_...\n",
       "15525     17  female   60  /opt/ml/data/train/images/005515_female_Asian_...\n",
       "\n",
       "[1344 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>locate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2912</th>\n      <td>2</td>\n      <td>male</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/001038_male_Asian_60...</td>\n    </tr>\n    <tr>\n      <th>2913</th>\n      <td>2</td>\n      <td>male</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/001038_male_Asian_60...</td>\n    </tr>\n    <tr>\n      <th>2914</th>\n      <td>8</td>\n      <td>male</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/001038_male_Asian_60...</td>\n    </tr>\n    <tr>\n      <th>2915</th>\n      <td>2</td>\n      <td>male</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/001038_male_Asian_60...</td>\n    </tr>\n    <tr>\n      <th>2916</th>\n      <td>2</td>\n      <td>male</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/001038_male_Asian_60...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15521</th>\n      <td>11</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n    </tr>\n    <tr>\n      <th>15522</th>\n      <td>5</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n    </tr>\n    <tr>\n      <th>15523</th>\n      <td>5</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n    </tr>\n    <tr>\n      <th>15524</th>\n      <td>5</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n    </tr>\n    <tr>\n      <th>15525</th>\n      <td>17</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1344 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "img = Image.open(over_60.iloc[15]['locate'])\n",
    "print(type(over_60))\n",
    "print(over_60.iloc[15]['locate'])\n",
    "over_60\n",
    "# img\n",
    "#apply lambda -> 쓰면 내가 원하는 동작 될거같다잉.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/opt/ml/data/train/images/001047_male_Asian_60/mask4_hf.jpg'"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "import cv2\n",
    "# img = Image.open(over_60.iloc[15]['locate'])\n",
    "\n",
    "ORIGIN_FILENAME = (\"normal\", \"mask1\", \"mask2\", \"mask3\", \"mask4\", \"mask5\", \"incorrect_mask\")\n",
    "REWRITE_FILENAME = (\"normal_hf\", \"mask1_hf\", \"mask2_hf\", \"mask3_hf\", \"mask4_hf\", \"mask5_hf\", \"incorrect_mask_hf\")\n",
    "file_rename = []\n",
    "transform = A.Compose([\n",
    "    # A.RandomCrop(width=256, height=256),\n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.Cutout(num_holes=1,max_h_size=100, max_w_size=100,p=0.7)\n",
    "])\n",
    "for image_locate in over_60['locate']:\n",
    "    img = cv2.imread(image_locate)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image_transform = transform(image=img)\n",
    "    # plt.imshow(a['image'])\n",
    "\n",
    "    loc_split = image_locate.split('/')\n",
    "    filename, extension = loc_split[-1].split('.')\n",
    "    loc_split[-1] = REWRITE_FILENAME[ORIGIN_FILENAME.index(filename)]+'.'+extension\n",
    "    rename_locate = '/'.join(loc_split)\n",
    "    file_rename.append(rename_locate)\n",
    "    # albumentation 처리된 후에 dict 로 반환되어 이미지만 따로 빼야함\n",
    "    cv2.imwrite(filename=rename_locate, img=image_transform['image'])\n",
    "# print(file_rename)\n",
    "over_60['locate'] = file_rename\n",
    "over_60.iloc[15]['locate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       label  gender  age                                               path  \\\n",
       "0          4  female   45  /opt/ml/data/train/images/000001_female_Asian_...   \n",
       "1          4  female   45  /opt/ml/data/train/images/000001_female_Asian_...   \n",
       "2         10  female   45  /opt/ml/data/train/images/000001_female_Asian_...   \n",
       "3          4  female   45  /opt/ml/data/train/images/000001_female_Asian_...   \n",
       "4          4  female   45  /opt/ml/data/train/images/000001_female_Asian_...   \n",
       "...      ...     ...  ...                                                ...   \n",
       "15521     11  female   60  /opt/ml/data/train/images/005515_female_Asian_...   \n",
       "15522      5  female   60  /opt/ml/data/train/images/005515_female_Asian_...   \n",
       "15523      5  female   60  /opt/ml/data/train/images/005515_female_Asian_...   \n",
       "15524      5  female   60  /opt/ml/data/train/images/005515_female_Asian_...   \n",
       "15525     17  female   60  /opt/ml/data/train/images/005515_female_Asian_...   \n",
       "\n",
       "             ga   race  \n",
       "0       4female  Asian  \n",
       "1       4female  Asian  \n",
       "2      10female  Asian  \n",
       "3       4female  Asian  \n",
       "4       4female  Asian  \n",
       "...         ...    ...  \n",
       "15521  11female  Asian  \n",
       "15522   5female  Asian  \n",
       "15523   5female  Asian  \n",
       "15524   5female  Asian  \n",
       "15525  17female  Asian  \n",
       "\n",
       "[20244 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>path</th>\n      <th>ga</th>\n      <th>race</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>4female</td>\n      <td>Asian</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>4female</td>\n      <td>Asian</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>10female</td>\n      <td>Asian</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>4female</td>\n      <td>Asian</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>4female</td>\n      <td>Asian</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15521</th>\n      <td>11</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n      <td>11female</td>\n      <td>Asian</td>\n    </tr>\n    <tr>\n      <th>15522</th>\n      <td>5</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n      <td>5female</td>\n      <td>Asian</td>\n    </tr>\n    <tr>\n      <th>15523</th>\n      <td>5</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n      <td>5female</td>\n      <td>Asian</td>\n    </tr>\n    <tr>\n      <th>15524</th>\n      <td>5</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n      <td>5female</td>\n      <td>Asian</td>\n    </tr>\n    <tr>\n      <th>15525</th>\n      <td>17</td>\n      <td>female</td>\n      <td>60</td>\n      <td>/opt/ml/data/train/images/005515_female_Asian_...</td>\n      <td>17female</td>\n      <td>Asian</td>\n    </tr>\n  </tbody>\n</table>\n<p>20244 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "total_data = data.append(over_60)\n",
    "\n",
    "total_data['ga'] = total_data['label'].astype(str) + total_data['gender']\n",
    "total_data['race'] = ['Asian' for i in range(len(total_data))]\n",
    "total_data.rename(columns={'locate':'path'}, inplace=True)\n",
    "total_data.to_csv('train.csv', sep=',', index=False)\n",
    "total_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, data, transform= None, train=True):\n",
    "        self.data = data\n",
    "        self.classes = self.data.columns.values.tolist()\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = Image.open(self.data['locate'].iloc[idx])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "    \n",
    "        if self.train:\n",
    "            y = self.data['label'].iloc[idx]\n",
    "            return X,y\n",
    "        \n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'You have to pass data to augmentations as named arguments, for example: aug(image=image)'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-70b9b47561a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_image_locate_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mimg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m821\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimg_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-bf7ff44a11c4>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/albumentations/core/transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to pass data to augmentations as named arguments, for example: aug(image=image)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplied_in_replay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'You have to pass data to augmentations as named arguments, for example: aug(image=image)'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(17)\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import *\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "transform = transforms.Compose([\n",
    "            # 선형 보간법을 사용하여 출력 픽셀값을 계산 -> 부드러운 느낌을 준다는데 누구 기준인진 잘\n",
    "            transforms.Resize((512,384), Image.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0.5, 0.5),\n",
    "            # transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.CenterCrop(384),\n",
    "            A.Cutout(num_holes=1, max_h_size=100, max_w_size=100, p=0.7),\n",
    "            ])\n",
    "datasets = MaskDataset(data=a.make_image_locate_frame(data), transform=transform, train=True)\n",
    "tf = transforms.ToPILImage()\n",
    "img_t = tf(datasets[821][0])\n",
    "print(datasets[1][0].shape)\n",
    "img_t\n",
    "# data_loader = Dataloader(datasets, num_workers=1, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n)\n0.001\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "models = models.resnet18(pretrained=True)\n",
    "optm = optim.Adam(models.parameters(), lr=0.001)\n",
    "lr = optim.lr_scheduler.ReduceLROnPlateau(optm, mode='max',factor=0.5, patience=2)\n",
    "print(lr.optimizer)\n",
    "print(optm.state_dict()['param_groups'][0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       age_group  gender  age  \\\n",
       "0              4  female   45   \n",
       "1              4  female   45   \n",
       "2             10  female   45   \n",
       "3              4  female   45   \n",
       "4              4  female   45   \n",
       "...          ...     ...  ...   \n",
       "18895          6    male   19   \n",
       "18896          0    male   19   \n",
       "18897          0    male   19   \n",
       "18898          0    male   19   \n",
       "18899         12    male   19   \n",
       "\n",
       "                                                    path   race        ga  \n",
       "0      /opt/ml/data/train/images/000001_female_Asian_...  Asian  45female  \n",
       "1      /opt/ml/data/train/images/000001_female_Asian_...  Asian  45female  \n",
       "2      /opt/ml/data/train/images/000001_female_Asian_...  Asian  45female  \n",
       "3      /opt/ml/data/train/images/000001_female_Asian_...  Asian  45female  \n",
       "4      /opt/ml/data/train/images/000001_female_Asian_...  Asian  45female  \n",
       "...                                                  ...    ...       ...  \n",
       "18895  /opt/ml/data/train/images/006959_male_Asian_19...  Asian    19male  \n",
       "18896  /opt/ml/data/train/images/006959_male_Asian_19...  Asian    19male  \n",
       "18897  /opt/ml/data/train/images/006959_male_Asian_19...  Asian    19male  \n",
       "18898  /opt/ml/data/train/images/006959_male_Asian_19...  Asian    19male  \n",
       "18899  /opt/ml/data/train/images/006959_male_Asian_19...  Asian    19male  \n",
       "\n",
       "[18900 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age_group</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>path</th>\n      <th>race</th>\n      <th>ga</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>Asian</td>\n      <td>45female</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>Asian</td>\n      <td>45female</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>Asian</td>\n      <td>45female</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>Asian</td>\n      <td>45female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>female</td>\n      <td>45</td>\n      <td>/opt/ml/data/train/images/000001_female_Asian_...</td>\n      <td>Asian</td>\n      <td>45female</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18895</th>\n      <td>6</td>\n      <td>male</td>\n      <td>19</td>\n      <td>/opt/ml/data/train/images/006959_male_Asian_19...</td>\n      <td>Asian</td>\n      <td>19male</td>\n    </tr>\n    <tr>\n      <th>18896</th>\n      <td>0</td>\n      <td>male</td>\n      <td>19</td>\n      <td>/opt/ml/data/train/images/006959_male_Asian_19...</td>\n      <td>Asian</td>\n      <td>19male</td>\n    </tr>\n    <tr>\n      <th>18897</th>\n      <td>0</td>\n      <td>male</td>\n      <td>19</td>\n      <td>/opt/ml/data/train/images/006959_male_Asian_19...</td>\n      <td>Asian</td>\n      <td>19male</td>\n    </tr>\n    <tr>\n      <th>18898</th>\n      <td>0</td>\n      <td>male</td>\n      <td>19</td>\n      <td>/opt/ml/data/train/images/006959_male_Asian_19...</td>\n      <td>Asian</td>\n      <td>19male</td>\n    </tr>\n    <tr>\n      <th>18899</th>\n      <td>12</td>\n      <td>male</td>\n      <td>19</td>\n      <td>/opt/ml/data/train/images/006959_male_Asian_19...</td>\n      <td>Asian</td>\n      <td>19male</td>\n    </tr>\n  </tbody>\n</table>\n<p>18900 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "loc.rename(columns={'locate':'path', 'label':'age_group'}, inplace=True)\n",
    "loc['race'] = ['Asian' for i in range(len(loc))]\n",
    "loc['ga'] = loc['age'].astype(str) + loc['gender']\n",
    "loc.to_csv('train_dt.csv', sep=',', index=False)\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      gender  age                    path   race  age_group        ga\n",
       "0     female   45  000001_female_Asian_45  Asian          1  45female\n",
       "1     female   52  000002_female_Asian_52  Asian          1  52female\n",
       "2       male   54    000004_male_Asian_54  Asian          1    54male\n",
       "3     female   58  000005_female_Asian_58  Asian          1  58female\n",
       "4     female   59  000006_female_Asian_59  Asian          1  59female\n",
       "...      ...  ...                     ...    ...        ...       ...\n",
       "2695    male   19    006954_male_Asian_19  Asian          0    19male\n",
       "2696    male   19    006955_male_Asian_19  Asian          0    19male\n",
       "2697    male   19    006956_male_Asian_19  Asian          0    19male\n",
       "2698    male   20    006957_male_Asian_20  Asian          0    20male\n",
       "2699    male   19    006959_male_Asian_19  Asian          0    19male\n",
       "\n",
       "[2700 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>path</th>\n      <th>race</th>\n      <th>age_group</th>\n      <th>ga</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>female</td>\n      <td>45</td>\n      <td>000001_female_Asian_45</td>\n      <td>Asian</td>\n      <td>1</td>\n      <td>45female</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>52</td>\n      <td>000002_female_Asian_52</td>\n      <td>Asian</td>\n      <td>1</td>\n      <td>52female</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>male</td>\n      <td>54</td>\n      <td>000004_male_Asian_54</td>\n      <td>Asian</td>\n      <td>1</td>\n      <td>54male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>female</td>\n      <td>58</td>\n      <td>000005_female_Asian_58</td>\n      <td>Asian</td>\n      <td>1</td>\n      <td>58female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>female</td>\n      <td>59</td>\n      <td>000006_female_Asian_59</td>\n      <td>Asian</td>\n      <td>1</td>\n      <td>59female</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2695</th>\n      <td>male</td>\n      <td>19</td>\n      <td>006954_male_Asian_19</td>\n      <td>Asian</td>\n      <td>0</td>\n      <td>19male</td>\n    </tr>\n    <tr>\n      <th>2696</th>\n      <td>male</td>\n      <td>19</td>\n      <td>006955_male_Asian_19</td>\n      <td>Asian</td>\n      <td>0</td>\n      <td>19male</td>\n    </tr>\n    <tr>\n      <th>2697</th>\n      <td>male</td>\n      <td>19</td>\n      <td>006956_male_Asian_19</td>\n      <td>Asian</td>\n      <td>0</td>\n      <td>19male</td>\n    </tr>\n    <tr>\n      <th>2698</th>\n      <td>male</td>\n      <td>20</td>\n      <td>006957_male_Asian_20</td>\n      <td>Asian</td>\n      <td>0</td>\n      <td>20male</td>\n    </tr>\n    <tr>\n      <th>2699</th>\n      <td>male</td>\n      <td>19</td>\n      <td>006959_male_Asian_19</td>\n      <td>Asian</td>\n      <td>0</td>\n      <td>19male</td>\n    </tr>\n  </tbody>\n</table>\n<p>2700 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "d = MakeLocateDataFrame(True)\n",
    "\n",
    "def label(x:int):\n",
    "    if x <30:\n",
    "        return 0\n",
    "    elif x <60:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "go = d.get_csv()\n",
    "go['race'] = ['Asian' for i in range(len(go))]\n",
    "go['age_group'] = go['age'].map(lambda x: label(x))\n",
    "go['ga'] = go['age'].astype(str) + go['gender']\n",
    "go.to_csv('train_dt.csv', sep=',', index=False)\n",
    "go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}