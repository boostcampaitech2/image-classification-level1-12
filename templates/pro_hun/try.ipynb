{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import datetime as dt\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.models.resnet import resnet152, resnet50\n",
    "from torchvision.transforms.transforms import GaussianBlur, RandomRotation\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from pytz import timezone\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import Normalize, Resize, ToTensor\n",
    "\n",
    "from data_preprocessing.data_split import Run_Split\n",
    "from utils.util import ensure_dir, prepare_device, notification\n",
    "from model.model import resnet_finetune\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "class Mask_Dataset(object):\n",
    "    def __init__(self, transforms, name, df):\n",
    "        self.transforms = transforms\n",
    "        self.name = name\n",
    "        self.imgs = list(\n",
    "            sorted(\n",
    "                os.listdir(\n",
    "                    f\"/opt/ml/image-classification-level1-12/templates/data/train/image_all/{self.name}_image\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img_path = Path(self.df[\"path\"][idx])\n",
    "        img_path = self.df[\"path\"][idx]\n",
    "        target = self.df[\"label\"][idx]\n",
    "        \n",
    "        # img = cv2.imread(img_path)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # if self.transforms is not None:\n",
    "        #     augmented = self.transforms(image = img)\n",
    "        #     img = augmented['image']\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "                \n",
    "        return img, target\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "train_path = \"/opt/ml/image-classification-level1-12/templates/data/train\"\n",
    "train_label = pd.read_csv(os.path.join(train_path, \"train_with_label.csv\"))\n",
    "run_split = Run_Split(os.path.join(train_path, \"image_all\"))\n",
    "fold_num = 5\n",
    "train_list, val_list = run_split.train_val_split(train_label, fold_num)\n",
    "\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "\t[\n",
    "\t\tResize((512, 384), Image.BILINEAR),\n",
    "\t\t# GaussianBlur(3, sigma=(0.1, 2)),\n",
    "\t\tRandomRotation([-8, +8]),\n",
    "\t\tToTensor(),\n",
    "\t\tNormalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "\t]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Mask_Dataset(data_transform, f\"train{i}\", train_list[i])\n",
    "train_loader = DataLoader(\n",
    "\ttrain_dataset,\n",
    "\tbatch_size=128,\n",
    "\t# 배치마다 어떤 작업을 해주고 싶을 때, 이미지 크기가 서로 맞지 않는 경우 맞춰줄 때 사용\n",
    "\tcollate_fn=collate_fn,\n",
    "\t# 마지막 남은 데이터가 배치 사이즈보다 작을 경우 무시\n",
    "\tdrop_last=False,\n",
    "\t#  num_workers=2\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model.medel'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-afcf111cc4fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_split\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRun_Split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mensure_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet_finetune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model.medel'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}