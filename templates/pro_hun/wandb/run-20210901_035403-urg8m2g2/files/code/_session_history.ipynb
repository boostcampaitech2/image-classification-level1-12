{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56dcaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask_Dataset(object):\n",
    "    def __init__(self, transforms, name, df, path, folder):\n",
    "        self.transforms = transforms\n",
    "        self.name = name\n",
    "        self.path = path\n",
    "        self.folder = folder\n",
    "        self.imgs = sorted(\n",
    "            os.listdir(os.path.join(self.path, f\"{self.folder}/{self.name}_image\"))\n",
    "        )\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img_path = Path(self.df[\"path\"][idx])\n",
    "        img_path = self.df[\"path\"][idx]\n",
    "        target = self.df[\"label\"][idx]\n",
    "\n",
    "        # img = cv2.imread(img_path)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # if self.transforms is not None:\n",
    "        #     augmented = self.transforms(image = img)\n",
    "        #     img = augmented['image']\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6bb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime as dt\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from pytz import timezone\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.resnet import resnet50, resnet152\n",
    "from torchvision.transforms import Normalize, Resize, ToTensor\n",
    "from torchvision.transforms.transforms import GaussianBlur, RandomRotation, RandomHorizontalFlip\n",
    "\n",
    "from data_preprocessing.data_split import Run_Split\n",
    "from model.loss import batch_loss\n",
    "from model.metric import batch_acc, batch_f1, epoch_mean\n",
    "from model.model import resnet_finetune, efficient_model\n",
    "from utils.util import ensure_dir, notification, prepare_device, fix_randomseed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc195e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.ArgumentParser(description=\"PyTorch Template\")\n",
    "args.add_argument(\n",
    "    \"-lr\",\n",
    "    \"--learning_rate\",\n",
    "    default=0.1,\n",
    "    type=float,\n",
    "    help=\"learning rate for training\",\n",
    ")\n",
    "args.add_argument(\n",
    "    \"-bs\", \"--batch_size\", default=4, type=int, help=\"batch size for training\"\n",
    ")\n",
    "args.add_argument(\"--epoch\", default=1, type=int, help=\"training epoch size\")\n",
    "args.add_argument(\"--fold_size\", default=1, type=int, help=\"StratifiedKFold size\")\n",
    "args.add_argument(\n",
    "    \"--train_path\",\n",
    "    default=\"/opt/ml/image-classification-level1-12/templates/data/train\",\n",
    "    type=str,\n",
    "    help=\"train_path\",\n",
    ")\n",
    "args.add_argument(\n",
    "    \"--model_save\",\n",
    "    default=\"/opt/ml/image-classification-level1-12/templates/pro_hun/output/model_save\",\n",
    "    type=str,\n",
    "    help=\"model_save_path\",\n",
    ")\n",
    "args.add_argument(\n",
    "    \"--normalize_mean\",\n",
    "    default=(0.5601, 0.5241, 0.5014),\n",
    "    type=float,\n",
    "    help=\"Normalize mean value\",\n",
    ")\n",
    "args.add_argument(\n",
    "    \"--normalize_std\",\n",
    "    default=(0.2331, 0.2430, 0.2456),\n",
    "    type=float,\n",
    "    help=\"Normalize std value\",\n",
    ")\n",
    "# Original:train_with_label.csv, Crop:train_with_crop.csv\n",
    "args.add_argument(\n",
    "    \"--image_data\",\n",
    "    default=\"train_with_label.csv\",\n",
    "    type=str,\n",
    "    help=\"Use Original or Original+Crop\",\n",
    ")\n",
    "# Original:image_folder, Crop:image_crop_all\n",
    "args.add_argument(\"--image_folder\", default=\"image_all\", type=str, help=\"Split_image folder\",)\n",
    "\n",
    "args = args.parse_args()\n",
    "config = wandb.config\n",
    "config.learning_rate = args.learning_rate\n",
    "fix_randomseed(12)\n",
    "\n",
    "train_path = args.train_path\n",
    "train_label = pd.read_csv(os.path.join(train_path, args.image_data))\n",
    "run_split = Run_Split(os.path.join(train_path, args.image_folder))\n",
    "fold_num = args.fold_size\n",
    "train_list, val_list = run_split.train_val_split(train_label, fold_num)\n",
    "\n",
    "# GPU가 사용가능하면 사용하고, 아니면 CPU 사용\n",
    "device = prepare_device()\n",
    "print(f\"{device} is using!\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# data_transform = albumentations.Compose([\n",
    "#     albumentations.Resize(512, 384, cv2.INTER_LINEAR),\n",
    "#     albumentations.Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "#     albumentations.OneOf([\n",
    "# \t\talbumentations.HorizontalFlip(p=1),\n",
    "# \t\talbumentations.Rotate([-10, 10], p=1),\n",
    "#     ], p=0.5),\n",
    "#     albumentations.pytorch.transforms.ToTensorV2(),\n",
    "#     # albumentations.RandomCrop(224, 224),\n",
    "#     # albumentations.RamdomCrop, CenterCrop, RandomRotation\n",
    "#     # albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()\n",
    "# ])\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        Resize((512, 384), Image.BILINEAR),\n",
    "        GaussianBlur(3, sigma=(0.1, 2)),\n",
    "        RandomHorizontalFlip(p=0.5),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=args.normalize_mean, std=args.normalize_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "now = (\n",
    "    dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d_%H%M%S\")\n",
    ")\n",
    "model_save_path = args.model_save\n",
    "dirname = os.path.join(model_save_path, f\"model_{now}\")\n",
    "ensure_dir(dirname)\n",
    "\n",
    "st_time = time.time()\n",
    "for i in range(fold_num):\n",
    "    # Resnent 18 네트워크의 Tensor들을 GPU에 올릴지 Memory에 올릴지 결정함\n",
    "    mnist_resnet = resnet_finetune(resnet18, 18).to(device)\n",
    "    wandb.watch(mnist_resnet)\n",
    "    # mnist_resnet = efficient_model('efficientnet-b0', 18).to(device)\n",
    "\n",
    "    # 분류 학습 때 많이 사용되는 Cross entropy loss를 objective function으로 사용 - https://en.wikipedia.org/wiki/Cross_entropy\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # weight 업데이트를 위한 optimizer를 Adam으로 사용함\n",
    "    optimizer = torch.optim.Adam(mnist_resnet.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    train_dataset = Mask_Dataset(\n",
    "        data_transform, f\"train{i}\", train_list[i], train_path, args.image_folder\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        # 배치마다 어떤 작업을 해주고 싶을 때, 이미지 크기가 서로 맞지 않는 경우 맞춰줄 때 사용\n",
    "        collate_fn=collate_fn,\n",
    "        # 마지막 남은 데이터가 배치 사이즈보다 작을 경우 무시\n",
    "        #  num_workers=2\n",
    "    )\n",
    "    val_dataset = Mask_Dataset(data_transform, f\"val{i}\", val_list[i], train_path, args.image_folder)\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        #  num_workers=2\n",
    "    )\n",
    "\n",
    "    dataloaders = {\"train\": train_loader, \"test\": val_loader}\n",
    "    TRAIN_FLAG = 'train'\n",
    "    TEST_FLAG = 'test'\n",
    "    ### 학습 코드 시작\n",
    "    best_test_accuracy = 0.0\n",
    "    best_test_loss = 9999.0\n",
    "\n",
    "    # flag = True\n",
    "    # early_ind = 0\n",
    "    pred_f1 = 0.0\n",
    "    for epoch in range(args.epoch):\n",
    "        # if not (flag):\n",
    "        #     break\n",
    "        for phase in [TRAIN_FLAG, TEST_FLAG]:\n",
    "            n_iter = 0\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            running_f1 = 0.0\n",
    "\n",
    "            if phase == TRAIN_FLAG:\n",
    "                mnist_resnet.train()  # 네트워크 모델을 train 모드로 두어 gradient을 계산하고, 여러 sub module (배치 정규화, 드롭아웃 등)이 train mode로 작동할 수 있도록 함\n",
    "            elif phase == TEST_FLAG:\n",
    "                mnist_resnet.eval()  # 네트워크 모델을 eval 모드 두어 여러 sub module들이 eval mode로 작동할 수 있게 함\n",
    "\n",
    "            for ind, (images, labels) in enumerate(\n",
    "                tqdm.tqdm(dataloaders[phase], leave=False)\n",
    "            ):\n",
    "                images = torch.stack(list(images), dim=0).to(device)\n",
    "                labels = torch.tensor(list(labels)).to(device)\n",
    "\n",
    "                optimizer.zero_grad()  # parameter gradient를 업데이트 전 초기화함\n",
    "\n",
    "                with torch.set_grad_enabled(\n",
    "                    phase == TRAIN_FLAG\n",
    "                ):  # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "                    logits = mnist_resnet(images)\n",
    "                    _, preds = torch.max(\n",
    "                        logits, 1\n",
    "                    )  # 모델에서 linear 값으로 나오는 예측 값 ([0.9,1.2, 3.2,0.1,-0.1,...])을 최대 output index를 찾아 예측 레이블([2])로 변경함\n",
    "                    loss = loss_fn(logits, labels)\n",
    "\n",
    "                    if phase == TRAIN_FLAG:\n",
    "                        loss.backward()  # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "                        optimizer.step()  # 계산된 gradient를 가지고 모델 업데이트\n",
    "\n",
    "                running_loss += batch_loss(loss, images)  # 한 Batch에서의 loss 값 저장\n",
    "                running_acc+= batch_acc(\n",
    "                    preds, labels.data\n",
    "                )  # 한 Batch에서의 Accuracy 값 저장\n",
    "                running_f1 += batch_f1(\n",
    "                    preds.cpu().numpy(), labels.cpu().numpy(), \"macro\"\n",
    "                )\n",
    "                n_iter += 1\n",
    "                if ind%100==0:\n",
    "                    wandb.log({'loss':loss})\n",
    "                    wandb.log({'acc':running_acc})\n",
    "                    wandb.log({'f1_score':running_f1})\n",
    "\n",
    "\n",
    "            # 한 epoch이 모두 종료되었을 때,\n",
    "            data_len = len(dataloaders[phase].dataset)\n",
    "            epoch_loss = epoch_mean(running_loss, data_len)\n",
    "            epoch_acc = epoch_mean(running_acc, data_len)\n",
    "            epoch_f1 = epoch_mean(running_f1, n_iter)\n",
    "\n",
    "            print(\n",
    "                f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}, F1 Score : {epoch_f1:.3f}\"\n",
    "            )\n",
    "            if (\n",
    "                phase == TEST_FLAG and best_test_accuracy < epoch_acc\n",
    "            ):  # phase가 test일 때, best accuracy 계산\n",
    "                best_test_accuracy = epoch_acc\n",
    "            if (\n",
    "                phase == TEST_FLAG and best_test_loss > epoch_loss\n",
    "            ):  # phase가 test일 때, best loss 계산\n",
    "                best_test_loss = epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bcbec5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">clean-bird-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/herjh0405/Mask_classification\" target=\"_blank\">https://wandb.ai/herjh0405/Mask_classification</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/herjh0405/Mask_classification/runs/urg8m2g2\" target=\"_blank\">https://wandb.ai/herjh0405/Mask_classification/runs/urg8m2g2</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/image-classification-level1-12/templates/pro_hun/wandb/run-20210901_035403-urg8m2g2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime as dt\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from pytz import timezone\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.resnet import resnet50, resnet152\n",
    "from torchvision.transforms import Normalize, Resize, ToTensor\n",
    "from torchvision.transforms.transforms import GaussianBlur, RandomRotation, RandomHorizontalFlip\n",
    "\n",
    "from data_preprocessing.data_split import Run_Split\n",
    "from model.loss import batch_loss\n",
    "from model.metric import batch_acc, batch_f1, epoch_mean\n",
    "from model.model import resnet_finetune, efficient_model\n",
    "from utils.util import ensure_dir, notification, prepare_device, fix_randomseed\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "\n",
    "class Mask_Dataset(object):\n",
    "    def __init__(self, transforms, name, df, path, folder):\n",
    "        self.transforms = transforms\n",
    "        self.name = name\n",
    "        self.path = path\n",
    "        self.folder = folder\n",
    "        self.imgs = sorted(\n",
    "            os.listdir(os.path.join(self.path, f\"{self.folder}/{self.name}_image\"))\n",
    "        )\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img_path = Path(self.df[\"path\"][idx])\n",
    "        img_path = self.df[\"path\"][idx]\n",
    "        target = self.df[\"label\"][idx]\n",
    "\n",
    "        # img = cv2.imread(img_path)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # if self.transforms is not None:\n",
    "        #     augmented = self.transforms(image = img)\n",
    "        #     img = augmented['image']\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.init(project='Mask_classification', entity='herjh0405')\n",
    "    args = argparse.ArgumentParser(description=\"PyTorch Template\")\n",
    "    args.add_argument(\n",
    "        \"-lr\",\n",
    "        \"--learning_rate\",\n",
    "        default=1,\n",
    "        type=float,\n",
    "        help=\"learning rate for training\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"-bs\", \"--batch_size\", default=4, type=int, help=\"batch size for training\"\n",
    "    )\n",
    "    args.add_argument(\"--epoch\", default=1, type=int, help=\"training epoch size\")\n",
    "    args.add_argument(\"--fold_size\", default=1, type=int, help=\"StratifiedKFold size\")\n",
    "    args.add_argument(\n",
    "        \"--train_path\",\n",
    "        default=\"/opt/ml/image-classification-level1-12/templates/data/train\",\n",
    "        type=str,\n",
    "        help=\"train_path\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--model_save\",\n",
    "        default=\"/opt/ml/image-classification-level1-12/templates/pro_hun/output/model_save\",\n",
    "        type=str,\n",
    "        help=\"model_save_path\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--normalize_mean\",\n",
    "        default=(0.5601, 0.5241, 0.5014),\n",
    "        type=float,\n",
    "        help=\"Normalize mean value\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--normalize_std\",\n",
    "        default=(0.2331, 0.2430, 0.2456),\n",
    "        type=float,\n",
    "        help=\"Normalize std value\",\n",
    "    )\n",
    "    # Original:train_with_label.csv, Crop:train_with_crop.csv\n",
    "    args.add_argument(\n",
    "        \"--image_data\",\n",
    "        default=\"train_with_label.csv\",\n",
    "        type=str,\n",
    "        help=\"Use Original or Original+Crop\",\n",
    "    )\n",
    "    # Original:image_folder, Crop:image_crop_all\n",
    "    args.add_argument(\"--image_folder\", default=\"image_all\", type=str, help=\"Split_image folder\",)\n",
    "\n",
    "    args = args.parse_args()\n",
    "    config = wandb.config\n",
    "    config.learning_rate = args.learning_rate\n",
    "    fix_randomseed(12)\n",
    "\n",
    "    train_path = args.train_path\n",
    "    train_label = pd.read_csv(os.path.join(train_path, args.image_data))\n",
    "    run_split = Run_Split(os.path.join(train_path, args.image_folder))\n",
    "    fold_num = args.fold_size\n",
    "    train_list, val_list = run_split.train_val_split(train_label, fold_num)\n",
    "\n",
    "    # GPU가 사용가능하면 사용하고, 아니면 CPU 사용\n",
    "    device = prepare_device()\n",
    "    print(f\"{device} is using!\")\n",
    "\n",
    "    # data_transform = albumentations.Compose([\n",
    "    #     albumentations.Resize(512, 384, cv2.INTER_LINEAR),\n",
    "    #     albumentations.Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "    #     albumentations.OneOf([\n",
    "    # \t\talbumentations.HorizontalFlip(p=1),\n",
    "    # \t\talbumentations.Rotate([-10, 10], p=1),\n",
    "    #     ], p=0.5),\n",
    "    #     albumentations.pytorch.transforms.ToTensorV2(),\n",
    "    #     # albumentations.RandomCrop(224, 224),\n",
    "    #     # albumentations.RamdomCrop, CenterCrop, RandomRotation\n",
    "    #     # albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()\n",
    "    # ])\n",
    "\n",
    "    data_transform = transforms.Compose(\n",
    "        [\n",
    "            Resize((512, 384), Image.BILINEAR),\n",
    "            GaussianBlur(3, sigma=(0.1, 2)),\n",
    "            RandomHorizontalFlip(p=0.5),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=args.normalize_mean, std=args.normalize_std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    now = (\n",
    "        dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    )\n",
    "    model_save_path = args.model_save\n",
    "    dirname = os.path.join(model_save_path, f\"model_{now}\")\n",
    "    ensure_dir(dirname)\n",
    "\n",
    "    st_time = time.time()\n",
    "    for i in range(fold_num):\n",
    "        # Resnent 18 네트워크의 Tensor들을 GPU에 올릴지 Memory에 올릴지 결정함\n",
    "        mnist_resnet = resnet_finetune(resnet18, 18).to(device)\n",
    "        wandb.watch(mnist_resnet)\n",
    "        # mnist_resnet = efficient_model('efficientnet-b0', 18).to(device)\n",
    "\n",
    "        # 분류 학습 때 많이 사용되는 Cross entropy loss를 objective function으로 사용 - https://en.wikipedia.org/wiki/Cross_entropy\n",
    "        loss_fn = FocalLoss()\n",
    "        # weight 업데이트를 위한 optimizer를 Adam으로 사용함\n",
    "        optimizer = torch.optim.Adam(mnist_resnet.parameters(), lr=args.learning_rate)\n",
    "\n",
    "        train_dataset = Mask_Dataset(\n",
    "            data_transform, f\"train{i}\", train_list[i], train_path, args.image_folder\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            # 배치마다 어떤 작업을 해주고 싶을 때, 이미지 크기가 서로 맞지 않는 경우 맞춰줄 때 사용\n",
    "            collate_fn=collate_fn,\n",
    "            # 마지막 남은 데이터가 배치 사이즈보다 작을 경우 무시\n",
    "            #  num_workers=2\n",
    "        )\n",
    "        val_dataset = Mask_Dataset(data_transform, f\"val{i}\", val_list[i], train_path, args.image_folder)\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            collate_fn=collate_fn,\n",
    "            #  num_workers=2\n",
    "        )\n",
    "\n",
    "        dataloaders = {\"train\": train_loader, \"test\": val_loader}\n",
    "        TRAIN_FLAG = 'train'\n",
    "        TEST_FLAG = 'test'\n",
    "        ### 학습 코드 시작\n",
    "        best_test_accuracy = 0.0\n",
    "        best_test_loss = 9999.0\n",
    "\n",
    "        # flag = True\n",
    "        # early_ind = 0\n",
    "        pred_f1 = 0.0\n",
    "        for epoch in range(args.epoch):\n",
    "            # if not (flag):\n",
    "            #     break\n",
    "            for phase in [TRAIN_FLAG, TEST_FLAG]:\n",
    "                n_iter = 0\n",
    "                running_loss = 0.0\n",
    "                running_acc = 0.0\n",
    "                running_f1 = 0.0\n",
    "\n",
    "                if phase == TRAIN_FLAG:\n",
    "                    mnist_resnet.train()  # 네트워크 모델을 train 모드로 두어 gradient을 계산하고, 여러 sub module (배치 정규화, 드롭아웃 등)이 train mode로 작동할 수 있도록 함\n",
    "                elif phase == TEST_FLAG:\n",
    "                    mnist_resnet.eval()  # 네트워크 모델을 eval 모드 두어 여러 sub module들이 eval mode로 작동할 수 있게 함\n",
    "\n",
    "                for ind, (images, labels) in enumerate(\n",
    "                    tqdm.tqdm(dataloaders[phase], leave=False)\n",
    "                ):\n",
    "                    images = torch.stack(list(images), dim=0).to(device)\n",
    "                    labels = torch.tensor(list(labels)).to(device)\n",
    "\n",
    "                    optimizer.zero_grad()  # parameter gradient를 업데이트 전 초기화함\n",
    "\n",
    "                    with torch.set_grad_enabled(\n",
    "                        phase == TRAIN_FLAG\n",
    "                    ):  # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "                        logits = mnist_resnet(images)\n",
    "                        _, preds = torch.max(\n",
    "                            logits, 1\n",
    "                        )  # 모델에서 linear 값으로 나오는 예측 값 ([0.9,1.2, 3.2,0.1,-0.1,...])을 최대 output index를 찾아 예측 레이블([2])로 변경함\n",
    "                        loss = loss_fn(logits, labels)\n",
    "\n",
    "                        if phase == TRAIN_FLAG:\n",
    "                            loss.backward()  # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "                            optimizer.step()  # 계산된 gradient를 가지고 모델 업데이트\n",
    "\n",
    "                    running_loss += batch_loss(loss, images)  # 한 Batch에서의 loss 값 저장\n",
    "                    running_acc+= batch_acc(\n",
    "                        preds, labels.data\n",
    "                    )  # 한 Batch에서의 Accuracy 값 저장\n",
    "                    running_f1 += batch_f1(\n",
    "                        preds.cpu().numpy(), labels.cpu().numpy(), \"macro\"\n",
    "                    )\n",
    "                    n_iter += 1\n",
    "                    if ind%100==0:\n",
    "                        wandb.log({'loss':loss})\n",
    "                        wandb.log({'acc':running_acc})\n",
    "                        wandb.log({'f1_score':running_f1})\n",
    "\n",
    "\n",
    "                # 한 epoch이 모두 종료되었을 때,\n",
    "                data_len = len(dataloaders[phase].dataset)\n",
    "                epoch_loss = epoch_mean(running_loss, data_len)\n",
    "                epoch_acc = epoch_mean(running_acc, data_len)\n",
    "                epoch_f1 = epoch_mean(running_f1, n_iter)\n",
    "\n",
    "                print(\n",
    "                    f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}, F1 Score : {epoch_f1:.3f}\"\n",
    "                )\n",
    "                if (\n",
    "                    phase == TEST_FLAG and best_test_accuracy < epoch_acc\n",
    "                ):  # phase가 test일 때, best accuracy 계산\n",
    "                    best_test_accuracy = epoch_acc\n",
    "                if (\n",
    "                    phase == TEST_FLAG and best_test_loss > epoch_loss\n",
    "                ):  # phase가 test일 때, best loss 계산\n",
    "                    best_test_loss = epoch_loss\n",
    "# e84afda8fca20c9a59d30a4768eec5aabd27135f\n",
    "                # Early Stopping Code\n",
    "                # if phase == TEST_FLAG:\n",
    "                #     if pred_f1 <= epoch_f1:\n",
    "                #         pred_f1 = epoch_f1\n",
    "                #         torch.save(mnist_resnet, os.path.join(dirname, f\"model_mnist{i}.pickle\"))\n",
    "                #         print(f\"{epoch}번째 모델 저장!\")\n",
    "                #         early_ind = 0\n",
    "                #     else:\n",
    "                #         print(f\"{epoch}번째 모델 pass\")\n",
    "                # early_ind += 1\n",
    "                # if early_ind == 2:\n",
    "                #     flag = False\n",
    "                #     break\n",
    "        torch.save(mnist_resnet, os.path.join(dirname, f\"model_mnist{i}.pickle\"))\n",
    "        print(\"학습 종료!\")\n",
    "        print(f\"최고 accuracy : {best_test_accuracy}, 최고 낮은 loss : {best_test_loss}\")\n",
    "    ed_time = time.time()\n",
    "    total_minute = (round(ed_time - st_time, 2)) // 60\n",
    "    print(f\"총 학습 시간 : {total_minute}분 소요되었습니다.\")\n",
    "    notification(best_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322e856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime as dt\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from pytz import timezone\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.resnet import resnet50, resnet152\n",
    "from torchvision.transforms import Normalize, Resize, ToTensor\n",
    "from torchvision.transforms.transforms import GaussianBlur, RandomRotation, RandomHorizontalFlip\n",
    "\n",
    "from data_preprocessing.data_split import Run_Split\n",
    "from model.loss import batch_loss\n",
    "from model.metric import batch_acc, batch_f1, epoch_mean\n",
    "from model.model import resnet_finetune, efficient_model\n",
    "from utils.util import ensure_dir, notification, prepare_device, fix_randomseed\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "\n",
    "class Mask_Dataset(object):\n",
    "    def __init__(self, transforms, name, df, path, folder):\n",
    "        self.transforms = transforms\n",
    "        self.name = name\n",
    "        self.path = path\n",
    "        self.folder = folder\n",
    "        self.imgs = sorted(\n",
    "            os.listdir(os.path.join(self.path, f\"{self.folder}/{self.name}_image\"))\n",
    "        )\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img_path = Path(self.df[\"path\"][idx])\n",
    "        img_path = self.df[\"path\"][idx]\n",
    "        target = self.df[\"label\"][idx]\n",
    "\n",
    "        # img = cv2.imread(img_path)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # if self.transforms is not None:\n",
    "        #     augmented = self.transforms(image = img)\n",
    "        #     img = augmented['image']\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.init(project='Mask_classification', entity='herjh0405')\n",
    "    args = argparse.ArgumentParser(description=\"PyTorch Template\")\n",
    "    args.add_argument(\n",
    "        \"-lr\",\n",
    "        \"--learning_rate\",\n",
    "        default=1,\n",
    "        type=float,\n",
    "        help=\"learning rate for training\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"-bs\", \"--batch_size\", default=4, type=int, help=\"batch size for training\"\n",
    "    )\n",
    "    args.add_argument(\"--epoch\", default=1, type=int, help=\"training epoch size\")\n",
    "    args.add_argument(\"--fold_size\", default=2, type=int, help=\"StratifiedKFold size\")\n",
    "    args.add_argument(\n",
    "        \"--train_path\",\n",
    "        default=\"/opt/ml/image-classification-level1-12/templates/data/train\",\n",
    "        type=str,\n",
    "        help=\"train_path\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--model_save\",\n",
    "        default=\"/opt/ml/image-classification-level1-12/templates/pro_hun/output/model_save\",\n",
    "        type=str,\n",
    "        help=\"model_save_path\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--normalize_mean\",\n",
    "        default=(0.5601, 0.5241, 0.5014),\n",
    "        type=float,\n",
    "        help=\"Normalize mean value\",\n",
    "    )\n",
    "    args.add_argument(\n",
    "        \"--normalize_std\",\n",
    "        default=(0.2331, 0.2430, 0.2456),\n",
    "        type=float,\n",
    "        help=\"Normalize std value\",\n",
    "    )\n",
    "    # Original:train_with_label.csv, Crop:train_with_crop.csv\n",
    "    args.add_argument(\n",
    "        \"--image_data\",\n",
    "        default=\"train_with_label.csv\",\n",
    "        type=str,\n",
    "        help=\"Use Original or Original+Crop\",\n",
    "    )\n",
    "    # Original:image_folder, Crop:image_crop_all\n",
    "    args.add_argument(\"--image_folder\", default=\"image_all\", type=str, help=\"Split_image folder\",)\n",
    "\n",
    "    args = args.parse_args()\n",
    "    config = wandb.config\n",
    "    config.learning_rate = args.learning_rate\n",
    "    fix_randomseed(12)\n",
    "\n",
    "    train_path = args.train_path\n",
    "    train_label = pd.read_csv(os.path.join(train_path, args.image_data))\n",
    "    run_split = Run_Split(os.path.join(train_path, args.image_folder))\n",
    "    fold_num = args.fold_size\n",
    "    train_list, val_list = run_split.train_val_split(train_label, fold_num)\n",
    "\n",
    "    # GPU가 사용가능하면 사용하고, 아니면 CPU 사용\n",
    "    device = prepare_device()\n",
    "    print(f\"{device} is using!\")\n",
    "\n",
    "    # data_transform = albumentations.Compose([\n",
    "    #     albumentations.Resize(512, 384, cv2.INTER_LINEAR),\n",
    "    #     albumentations.Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "    #     albumentations.OneOf([\n",
    "    # \t\talbumentations.HorizontalFlip(p=1),\n",
    "    # \t\talbumentations.Rotate([-10, 10], p=1),\n",
    "    #     ], p=0.5),\n",
    "    #     albumentations.pytorch.transforms.ToTensorV2(),\n",
    "    #     # albumentations.RandomCrop(224, 224),\n",
    "    #     # albumentations.RamdomCrop, CenterCrop, RandomRotation\n",
    "    #     # albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()\n",
    "    # ])\n",
    "\n",
    "    data_transform = transforms.Compose(\n",
    "        [\n",
    "            Resize((512, 384), Image.BILINEAR),\n",
    "            GaussianBlur(3, sigma=(0.1, 2)),\n",
    "            RandomHorizontalFlip(p=0.5),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=args.normalize_mean, std=args.normalize_std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    now = (\n",
    "        dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    )\n",
    "    model_save_path = args.model_save\n",
    "    dirname = os.path.join(model_save_path, f\"model_{now}\")\n",
    "    ensure_dir(dirname)\n",
    "\n",
    "    st_time = time.time()\n",
    "    for i in range(fold_num):\n",
    "        # Resnent 18 네트워크의 Tensor들을 GPU에 올릴지 Memory에 올릴지 결정함\n",
    "        mnist_resnet = resnet_finetune(resnet18, 18).to(device)\n",
    "        # mnist_resnet = efficient_model('efficientnet-b0', 18).to(device)\n",
    "\n",
    "        # 분류 학습 때 많이 사용되는 Cross entropy loss를 objective function으로 사용 - https://en.wikipedia.org/wiki/Cross_entropy\n",
    "        loss_fn = FocalLoss()\n",
    "        # weight 업데이트를 위한 optimizer를 Adam으로 사용함\n",
    "        optimizer = torch.optim.Adam(mnist_resnet.parameters(), lr=args.learning_rate)\n",
    "\n",
    "        train_dataset = Mask_Dataset(\n",
    "            data_transform, f\"train{i}\", train_list[i], train_path, args.image_folder\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            # 배치마다 어떤 작업을 해주고 싶을 때, 이미지 크기가 서로 맞지 않는 경우 맞춰줄 때 사용\n",
    "            collate_fn=collate_fn,\n",
    "            # 마지막 남은 데이터가 배치 사이즈보다 작을 경우 무시\n",
    "            #  num_workers=2\n",
    "        )\n",
    "        val_dataset = Mask_Dataset(data_transform, f\"val{i}\", val_list[i], train_path, args.image_folder)\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            collate_fn=collate_fn,\n",
    "            #  num_workers=2\n",
    "        )\n",
    "\n",
    "        dataloaders = {\"train\": train_loader, \"test\": val_loader}\n",
    "        TRAIN_FLAG = 'train'\n",
    "        TEST_FLAG = 'test'\n",
    "        ### 학습 코드 시작\n",
    "        best_test_accuracy = 0.0\n",
    "        best_test_loss = 9999.0\n",
    "\n",
    "        # flag = True\n",
    "        # early_ind = 0\n",
    "        pred_f1 = 0.0\n",
    "        for epoch in range(args.epoch):\n",
    "            # if not (flag):\n",
    "            #     break\n",
    "            for phase in [TRAIN_FLAG, TEST_FLAG]:\n",
    "                n_iter = 0\n",
    "                running_loss = 0.0\n",
    "                running_acc = 0.0\n",
    "                running_f1 = 0.0\n",
    "\n",
    "                if phase == TRAIN_FLAG:\n",
    "                    mnist_resnet.train()  # 네트워크 모델을 train 모드로 두어 gradient을 계산하고, 여러 sub module (배치 정규화, 드롭아웃 등)이 train mode로 작동할 수 있도록 함\n",
    "                elif phase == TEST_FLAG:\n",
    "                    mnist_resnet.eval()  # 네트워크 모델을 eval 모드 두어 여러 sub module들이 eval mode로 작동할 수 있게 함\n",
    "\n",
    "                for ind, (images, labels) in enumerate(\n",
    "                    tqdm.tqdm(dataloaders[phase], leave=False)\n",
    "                ):\n",
    "                    images = torch.stack(list(images), dim=0).to(device)\n",
    "                    labels = torch.tensor(list(labels)).to(device)\n",
    "\n",
    "                    optimizer.zero_grad()  # parameter gradient를 업데이트 전 초기화함\n",
    "\n",
    "                    with torch.set_grad_enabled(\n",
    "                        phase == TRAIN_FLAG\n",
    "                    ):  # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "                        logits = mnist_resnet(images)\n",
    "                        _, preds = torch.max(\n",
    "                            logits, 1\n",
    "                        )  # 모델에서 linear 값으로 나오는 예측 값 ([0.9,1.2, 3.2,0.1,-0.1,...])을 최대 output index를 찾아 예측 레이블([2])로 변경함\n",
    "                        loss = loss_fn(logits, labels)\n",
    "\n",
    "                        if phase == TRAIN_FLAG:\n",
    "                            loss.backward()  # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "                            optimizer.step()  # 계산된 gradient를 가지고 모델 업데이트\n",
    "\n",
    "                    running_loss += batch_loss(loss, images)  # 한 Batch에서의 loss 값 저장\n",
    "                    running_acc+= batch_acc(\n",
    "                        preds, labels.data\n",
    "                    )  # 한 Batch에서의 Accuracy 값 저장\n",
    "                    running_f1 += batch_f1(\n",
    "                        preds.cpu().numpy(), labels.cpu().numpy(), \"macro\"\n",
    "                    )\n",
    "                    n_iter += 1\n",
    "\n",
    "\n",
    "                # 한 epoch이 모두 종료되었을 때,\n",
    "                data_len = len(dataloaders[phase].dataset)\n",
    "                epoch_loss = epoch_mean(running_loss, data_len)\n",
    "                epoch_acc = epoch_mean(running_acc, data_len)\n",
    "                epoch_f1 = epoch_mean(running_f1, n_iter)\n",
    "\n",
    "                print(\n",
    "                    f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}, F1 Score : {epoch_f1:.3f}\"\n",
    "                )\n",
    "                if (\n",
    "                    phase == TEST_FLAG and best_test_accuracy < epoch_acc\n",
    "                ):  # phase가 test일 때, best accuracy 계산\n",
    "                    best_test_accuracy = epoch_acc\n",
    "                if (\n",
    "                    phase == TEST_FLAG and best_test_loss > epoch_loss\n",
    "                ):  # phase가 test일 때, best loss 계산\n",
    "                    best_test_loss = epoch_loss\n",
    "# e84afda8fca20c9a59d30a4768eec5aabd27135f\n",
    "                # Early Stopping Code\n",
    "                # if phase == TEST_FLAG:\n",
    "                #     if pred_f1 <= epoch_f1:\n",
    "                #         pred_f1 = epoch_f1\n",
    "                #         torch.save(mnist_resnet, os.path.join(dirname, f\"model_mnist{i}.pickle\"))\n",
    "                #         print(f\"{epoch}번째 모델 저장!\")\n",
    "                #         early_ind = 0\n",
    "                #     else:\n",
    "                #         print(f\"{epoch}번째 모델 pass\")\n",
    "                # early_ind += 1\n",
    "                # if early_ind == 2:\n",
    "                #     flag = False\n",
    "                #     break\n",
    "        torch.save(mnist_resnet, os.path.join(dirname, f\"model_mnist{i}.pickle\"))\n",
    "        print(\"학습 종료!\")\n",
    "        print(f\"최고 accuracy : {best_test_accuracy}, 최고 낮은 loss : {best_test_loss}\")\n",
    "    ed_time = time.time()\n",
    "    total_minute = (round(ed_time - st_time, 2)) // 60\n",
    "    print(f\"총 학습 시간 : {total_minute}분 소요되었습니다.\")\n",
    "    notification(best_test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
